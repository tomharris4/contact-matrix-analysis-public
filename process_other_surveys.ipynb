{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6facb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0d9062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHINA, 2020\n",
    "\n",
    "# Surveys to analyse\n",
    "file = 'Data/China, 2020'\n",
    "\n",
    "\n",
    "# countries = []\n",
    "\n",
    "\n",
    "# define country name\n",
    "country = 'China'\n",
    "\n",
    "# get contact extra filename\n",
    "dir_contents = listdir(file)\n",
    "r = re.compile(\".*contact_extra.csv\")\n",
    "filename = file + '/' + list(filter(r.match, dir_contents))[0]\n",
    "\n",
    "contact_extra = pd.read_csv(filename)\n",
    "\n",
    "# get participant extra filename\n",
    "dir_contents = listdir(file)\n",
    "r = re.compile(\".*participant_extra.csv\")\n",
    "filename = file + '/' + list(filter(r.match, dir_contents))[0]\n",
    "\n",
    "part_extra = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "raw = file + '/Raw'\n",
    "\n",
    "dir_contents = listdir(raw)\n",
    "r = re.compile(\".*contact_common.csv\")\n",
    "filename = raw + '/' + list(filter(r.match, dir_contents))[0]\n",
    "\n",
    "# countries.append((country,filename[-21:-19]))\n",
    "\n",
    "data_contacts = pd.read_csv(filename)\n",
    "\n",
    "merged_contacts = pd.merge(contact_extra, data_contacts, on=\"cont_id\", how='right')\n",
    "\n",
    "merged_contacts = pd.merge(part_extra, merged_contacts, on=\"part_id\", how='right')\n",
    "\n",
    "data_contacts['survey_location'] = merged_contacts['survey_location']\n",
    "\n",
    "data_contacts['collection_period'] = merged_contacts['collection_period']\n",
    "\n",
    "dir_contents = listdir(raw)\n",
    "r = re.compile(\".*participant_common.csv\")\n",
    "filename = raw + '/' + list(filter(r.match, dir_contents))[0]\n",
    "\n",
    "data_parts = pd.read_csv(filename)\n",
    "\n",
    "merged_parts = pd.merge(part_extra, data_parts, on=\"part_id\", how='right')\n",
    "\n",
    "\n",
    "data_parts['survey_location'] = merged_parts['survey_location']\n",
    "\n",
    "\n",
    "# split contacts data\n",
    "\n",
    "wuhan_baseline_contacts = data_contacts.loc[(data_contacts['survey_location'] == 'Wuhan') & \n",
    "                                            (data_contacts['collection_period'] == 'baseline')]\n",
    "wuhan_outbreak_contacts = data_contacts.loc[(data_contacts['survey_location'] == 'Wuhan') & \n",
    "                                            (data_contacts['collection_period'] == 'outbreak')]\n",
    "shanghai_baseline_contacts = data_contacts.loc[(data_contacts['survey_location'] == 'Shanghai') & \n",
    "                                            (data_contacts['collection_period'] == 'baseline')]\n",
    "shanghai_outbreak_contacts = data_contacts.loc[(data_contacts['survey_location'] == 'Shanghai') & \n",
    "                                            (data_contacts['collection_period'] == 'outbreak')]\n",
    "\n",
    "\n",
    "wuhan_baseline_contacts = wuhan_baseline_contacts.drop('survey_location', axis=1)\n",
    "wuhan_baseline_contacts = wuhan_baseline_contacts.drop('collection_period', axis=1).set_index('part_id')\n",
    "wuhan_outbreak_contacts = wuhan_outbreak_contacts.drop('survey_location', axis=1)\n",
    "wuhan_outbreak_contacts = wuhan_outbreak_contacts.drop('collection_period', axis=1).set_index('part_id')\n",
    "\n",
    "shanghai_baseline_contacts = shanghai_baseline_contacts.drop('survey_location', axis=1)\n",
    "shanghai_baseline_contacts = shanghai_baseline_contacts.drop('collection_period', axis=1).set_index('part_id')\n",
    "shanghai_outbreak_contacts = shanghai_outbreak_contacts.drop('survey_location', axis=1)\n",
    "shanghai_outbreak_contacts = shanghai_outbreak_contacts.drop('collection_period', axis=1).set_index('part_id')\n",
    "\n",
    "wuhan_baseline_contacts.to_csv('Data/China, 2020/Filtered/Wuhan_baseline/Raw/2020_Zhang_China_contact_common.csv', na_rep='NA')\n",
    "wuhan_outbreak_contacts.to_csv('Data/China, 2020/Filtered/Wuhan_outbreak/Raw/2020_Zhang_China_contact_common.csv', na_rep='NA')\n",
    "shanghai_baseline_contacts.to_csv('Data/China, 2020/Filtered/Shanghai_baseline/Raw/2020_Zhang_China_contact_common.csv', na_rep='NA')\n",
    "shanghai_outbreak_contacts.to_csv('Data/China, 2020/Filtered/Shanghai_outbreak/Raw/2020_Zhang_China_contact_common.csv', na_rep='NA')\n",
    "\n",
    "\n",
    "# split participants data\n",
    "\n",
    "wuhan_baseline_parts = data_parts.loc[data_parts['survey_location'] == 'Wuhan']\n",
    "wuhan_outbreak_parts = data_parts.loc[data_parts['survey_location'] == 'Wuhan']\n",
    "shanghai_baseline_parts = data_parts.loc[data_parts['survey_location'] == 'Shanghai']\n",
    "shanghai_outbreak_parts = data_parts.loc[data_parts['survey_location'] == 'Shanghai']\n",
    "\n",
    "wuhan_baseline_parts = wuhan_baseline_parts.drop('survey_location', axis=1).set_index('part_id')\n",
    "wuhan_outbreak_parts = wuhan_outbreak_parts.drop('survey_location', axis=1).set_index('part_id')\n",
    "\n",
    "shanghai_baseline_parts = shanghai_baseline_parts.drop('survey_location', axis=1).set_index('part_id')\n",
    "shanghai_outbreak_parts = shanghai_outbreak_parts.drop('survey_location', axis=1).set_index('part_id')\n",
    "\n",
    "wuhan_baseline_parts.to_csv('Data/China, 2020/Filtered/Wuhan_baseline/Raw/2020_Zhang_China_participant_common.csv', na_rep='NA')\n",
    "wuhan_outbreak_parts.to_csv('Data/China, 2020/Filtered/Wuhan_outbreak/Raw/2020_Zhang_China_participant_common.csv', na_rep='NA')\n",
    "shanghai_baseline_parts.to_csv('Data/China, 2020/Filtered/Shanghai_baseline/Raw/2020_Zhang_China_participant_common.csv', na_rep='NA')\n",
    "shanghai_outbreak_parts.to_csv('Data/China, 2020/Filtered/Shanghai_outbreak/Raw/2020_Zhang_China_participant_common.csv', na_rep='NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92c517cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZIMBABWE\n",
    "\n",
    "# Surveys to analyse\n",
    "file = 'Data/Zimbabwe'\n",
    "\n",
    "# define country name\n",
    "country = 'Zimbabwe'\n",
    "\n",
    "# get contact extra filename\n",
    "dir_contents = listdir(file)\n",
    "r = re.compile(\".*participant_extra.csv\")\n",
    "filename = file + '/' + list(filter(r.match, dir_contents))[0]\n",
    "\n",
    "part_extra = pd.read_csv(filename)\n",
    "\n",
    "raw = file + '/Raw'\n",
    "\n",
    "dir_contents = listdir(raw)\n",
    "r = re.compile(\".*contact_common.csv\")\n",
    "filename = raw + '/' + list(filter(r.match, dir_contents))[0]\n",
    "\n",
    "# countries.append((country,filename[-21:-19]))\n",
    "\n",
    "data_contacts = pd.read_csv(filename)\n",
    "\n",
    "merged_contacts = pd.merge(part_extra, data_contacts, on=\"part_id\", how='right')\n",
    "\n",
    "data_contacts['study_site'] = merged_contacts['study_site']\n",
    "\n",
    "dir_contents = listdir(raw)\n",
    "r = re.compile(\".*participant_common.csv\")\n",
    "filename = raw + '/' + list(filter(r.match, dir_contents))[0]\n",
    "\n",
    "data_parts = pd.read_csv(filename)\n",
    "\n",
    "merged_parts = pd.merge(part_extra, data_parts, on=\"part_id\", how='right')\n",
    "\n",
    "data_parts['study_site'] = merged_parts['study_site']\n",
    "\n",
    "\n",
    "# split contacts data\n",
    "\n",
    "peri_urban_contacts = data_contacts.loc[(data_contacts['study_site'] == 2)]\n",
    "farm_contacts = data_contacts.loc[(data_contacts['study_site'] == 1)]\n",
    "\n",
    "peri_urban_contacts = peri_urban_contacts.drop('study_site', axis=1).set_index('part_id')\n",
    "farm_contacts = farm_contacts.drop('study_site', axis=1).set_index('part_id')\n",
    "\n",
    "peri_urban_contacts.to_csv('Data/Zimbabwe/Filtered/Peri_urban/Raw/2017_Melegaro_Zimbabwe_contact_common.csv', na_rep='NA')\n",
    "farm_contacts.to_csv('Data/Zimbabwe/Filtered/Farm/Raw/2017_Melegaro_Zimbabwe_contact_common.csv', na_rep='NA')\n",
    "\n",
    "# split participants data\n",
    "\n",
    "peri_urban_parts = data_parts.loc[(data_parts['study_site'] == 2)]\n",
    "farm_parts = data_parts.loc[(data_parts['study_site'] == 1)]\n",
    "\n",
    "peri_urban_parts = peri_urban_parts.drop('study_site', axis=1).set_index('part_id')\n",
    "farm_parts = farm_parts.drop('study_site', axis=1).set_index('part_id')\n",
    "\n",
    "peri_urban_parts.to_csv('Data/Zimbabwe/Filtered/Peri_urban/Raw/2017_Melegaro_Zimbabwe_participant_common.csv', na_rep='NA')\n",
    "farm_parts.to_csv('Data/Zimbabwe/Filtered/Farm/Raw/2017_Melegaro_Zimbabwe_participant_common.csv', na_rep='NA')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
