{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc3fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import re\n",
    "from datetime import date\n",
    "\n",
    "stringency_dic = {}\n",
    "\n",
    "# Read in stringency index data\n",
    "with open('Data/stringency_index_avg.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    next(reader, None)  # skip the headers\n",
    "    for row in reader:\n",
    "        if list(row)[5] == 'NAT_TOTAL':\n",
    "            stringency_dic[list(row)[2]] = list(row)[6:]\n",
    "        \n",
    "    \n",
    "stringency_table = pd.DataFrame(data=stringency_dic)\n",
    "\n",
    "# Align name for 'Slovakia' with comix name\n",
    "stringency_table.rename(columns={'Slovak Republic': 'Slovakia'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "860f9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = date(2020,1,1)\n",
    "\n",
    "# Compute number of days since 1/1/2020\n",
    "def convertDate(survey_date):\n",
    "    \n",
    "    if str(survey_date)=='nan':\n",
    "        return None\n",
    "    \n",
    "    if len(survey_date) < 10:\n",
    "        print('Invalid date format')\n",
    "        return None\n",
    "    \n",
    "    year = int(survey_date[0:4])\n",
    "    \n",
    "    month = int(survey_date[5:7])\n",
    "    \n",
    "    day = int(survey_date[8:10])\n",
    "    \n",
    "    date_out = date(year,month,day)\n",
    "    \n",
    "    return (date_out-start).days\n",
    "\n",
    "\n",
    "# Compute average stringency across all survey days\n",
    "def getAvgStringency(country,dates):\n",
    "    \n",
    "    stringency_vals = []\n",
    "    \n",
    "    for d in dates:\n",
    "        \n",
    "        d_converted = convertDate(d)\n",
    "        \n",
    "        if d_converted:\n",
    "            stringency_vals.append(float(stringency_table[country][d_converted]))\n",
    "        \n",
    "    return np.mean(stringency_vals)\n",
    "\n",
    "# Compute all stringency values and dates across all survey days\n",
    "def getStringency(country,dates):\n",
    "    \n",
    "    stringency_vals = []\n",
    "    \n",
    "    dates_out = []\n",
    "    \n",
    "    for d in dates:\n",
    "        \n",
    "        d_converted = convertDate(d)\n",
    "        \n",
    "        dates_out.append(d_converted)\n",
    "        \n",
    "        if d_converted:\n",
    "            stringency_vals.append(float(stringency_table[country][d_converted]))\n",
    "        \n",
    "    return (stringency_vals, dates_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7399cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UK STRINGENCY INVESTIGATION\n",
    "\n",
    "# Assign stringency value to each participant and contact based on intervention stringency on survey day\n",
    "\n",
    "comix_files = ['Data/United Kingdom (C)']\n",
    "\n",
    "\n",
    "for file in comix_files:\n",
    "    \n",
    "    # define country name\n",
    "    country = file[5:-4]\n",
    "    \n",
    "    # get sday filename\n",
    "    dir_contents = listdir(file)\n",
    "    r = re.compile(\".*sday.csv\")\n",
    "    filename = file + '/' + list(filter(r.match, dir_contents))[0]\n",
    "    \n",
    "    data_day = pd.read_csv(filename)\n",
    "    \n",
    "    proc = file + '/Processed'\n",
    "    \n",
    "    dir_contents = listdir(proc)\n",
    "    r = re.compile(\".*contact_common.csv\")\n",
    "    filename = proc + '/' + list(filter(r.match, dir_contents))[0]\n",
    "    \n",
    "    data_contacts = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "    merged_contacts = pd.merge(data_day, data_contacts, on=\"part_id\", how='right')\n",
    "    \n",
    "    data_si_contacts = getStringency('United Kingdom', merged_contacts['sday_id'])\n",
    "    \n",
    "    data_contacts['si'] = data_si_contacts[0]\n",
    "    \n",
    "    dir_contents = listdir(proc)\n",
    "    r = re.compile(\".*participant_common.csv\")\n",
    "    filename = proc + '/' + list(filter(r.match, dir_contents))[0]\n",
    "    \n",
    "    data_parts = pd.read_csv(filename)\n",
    "    \n",
    "    merged_parts = pd.merge(data_day, data_parts, on=\"part_id\", how='right')\n",
    "    \n",
    "    data_si_parts = getStringency('United Kingdom', merged_parts['sday_id'])\n",
    "    \n",
    "    data_parts['si'] = data_si_parts[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c0f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter survey into contact events occurring on survey days with intervention stringency between the split values\n",
    "\n",
    "splits = [40,55,70]\n",
    "\n",
    "weakest_contacts = data_contacts.loc[data_contacts['si'] <= splits[0]]\n",
    "weak_contacts = data_contacts.loc[(data_contacts['si'] > splits[0]) & (data_contacts['si'] <= splits[1])]\n",
    "strong_contacts = data_contacts.loc[(data_contacts['si'] > splits[1]) & (data_contacts['si'] <= splits[2])]\n",
    "strongest_contacts = data_contacts.loc[data_contacts['si'] > splits[2]]\n",
    "\n",
    "weakest_contacts = weakest_contacts.drop('si', axis=1)\n",
    "weak_contacts = weak_contacts.drop('si', axis=1)\n",
    "strong_contacts = strong_contacts.drop('si', axis=1)\n",
    "strongest_contacts = strongest_contacts.drop('si', axis=1)\n",
    "\n",
    "weakest_contacts = weakest_contacts.set_index('part_id')                                    \n",
    "weak_contacts = weak_contacts.set_index('part_id')\n",
    "strong_contacts = strong_contacts.set_index('part_id')\n",
    "strongest_contacts = strongest_contacts.set_index('part_id')\n",
    "\n",
    "weakest_contacts.to_csv('Data/United Kingdom (C)/Filtered/Weakest/CoMix_uk_contact_common.csv', na_rep='NA')                                    \n",
    "weak_contacts.to_csv('Data/United Kingdom (C)/Filtered/Weak/CoMix_uk_contact_common.csv', na_rep='NA')\n",
    "strong_contacts.to_csv('Data/United Kingdom (C)/Filtered/Strong/CoMix_uk_contact_common.csv', na_rep='NA')\n",
    "strongest_contacts.to_csv('Data/United Kingdom (C)/Filtered/Strongest/CoMix_uk_contact_common.csv', na_rep='NA')                                    \n",
    "\n",
    "weakest_parts = data_parts.loc[data_parts['si'] <= splits[0]]\n",
    "weak_parts = data_parts.loc[(data_parts['si'] > splits[0]) & (data_parts['si'] <= splits[1])]\n",
    "strong_parts = data_parts.loc[(data_parts['si'] > splits[1]) & (data_parts['si'] <= splits[2])]\n",
    "strongest_parts = data_parts.loc[data_parts['si'] > splits[2]]\n",
    "\n",
    "weakest_parts = weakest_parts.drop('si', axis=1)                              \n",
    "weak_parts = weak_parts.drop('si', axis=1)\n",
    "strong_parts = strong_parts.drop('si', axis=1)\n",
    "strongest_parts = strongest_parts.drop('si', axis=1)\n",
    "                              \n",
    "weakest_parts = weakest_parts.set_index('part_id')\n",
    "weak_parts = weak_parts.set_index('part_id')\n",
    "strong_parts = strong_parts.set_index('part_id')\n",
    "strongest_parts = strongest_parts.set_index('part_id')\n",
    "\n",
    "weakest_parts.to_csv('Data/United Kingdom (C)/Filtered/Weakest/CoMix_uk_participant_common.csv', na_rep='NA')                              \n",
    "weak_parts.to_csv('Data/United Kingdom (C)/Filtered/Weak/CoMix_uk_participant_common.csv', na_rep='NA')\n",
    "strong_parts.to_csv('Data/United Kingdom (C)/Filtered/Strong/CoMix_uk_participant_common.csv', na_rep='NA')\n",
    "strongest_parts.to_csv('Data/United Kingdom (C)/Filtered/Strongest/CoMix_uk_participant_common.csv', na_rep='NA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
